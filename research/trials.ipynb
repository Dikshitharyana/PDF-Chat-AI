{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78316a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "\n",
    "# Load PDFs from a directory\n",
    "def load_pdf_directory(data_dir):\n",
    "    loader = PyPDFDirectoryLoader(data_dir)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# Load a single PDF file\n",
    "def load_pdf_file(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "# Split the text into smaller chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "# Download the embeddings from huggingface\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf2c694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dikshit\\miniconda3\\envs\\pdfbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, jsonify, request\n",
    "import os\n",
    "from werkzeug.utils import secure_filename\n",
    "from src.helper import text_split, download_hugging_face_embeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_together import ChatTogether\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from src.prompt import *\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561bb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from werkzeug.utils import secure_filename\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from src.helper import text_split, download_hugging_face_embeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01051ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load keys and init\n",
    "load_dotenv()  \n",
    "API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "assert API_KEY, \"PINECONE_API_KEY not set in .env!\"\n",
    "\n",
    "# set for pinecone-client\n",
    "os.environ[\"PINECONE_API_KEY\"] = API_KEY\n",
    "pc = Pinecone(api_key=API_KEY)\n",
    "\n",
    "# Choose your test index name\n",
    "INDEX_NAME = \"pdfbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86a5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: port your helper function\n",
    "def process_uploaded_pdfs(file_paths, session_id):\n",
    "    # load + chunk\n",
    "    docs = []\n",
    "    for fp in file_paths:\n",
    "        loader = PyPDFLoader(fp)\n",
    "        docs.extend(loader.load())\n",
    "    chunks = text_split(docs)\n",
    "    \n",
    "    # embeddings\n",
    "    emb = download_hugging_face_embeddings()\n",
    "    \n",
    "    # ensure index exists\n",
    "    existing = pc.list_indexes()  # returns List[str]\n",
    "    if INDEX_NAME not in existing:\n",
    "        pc.create_index(name=INDEX_NAME, dimension=384, metric=\"cosine\")\n",
    "        print(f\"➡️ Created index {INDEX_NAME}\")\n",
    "    else:\n",
    "        print(f\"✅ Index {INDEX_NAME} already exists\")\n",
    "    \n",
    "    # upsert\n",
    "    vs = PineconeVectorStore.from_documents(\n",
    "        documents=chunks,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=emb,\n",
    "        namespace=session_id\n",
    "    )\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b6205a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path Data/Brown-Giving-PsychSci-2003.pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m uploaded \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/Brown-Giving-PsychSci-2003.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# adjust path as needed\u001b[39;00m\n\u001b[0;32m      3\u001b[0m session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n\u001b[1;32m----> 4\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_uploaded_pdfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43muploaded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check how many vectors you now have\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectors upserted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, vector_store\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mdescribe_index(INDEX_NAME)\u001b[38;5;241m.\u001b[39mnamespaces[session]\u001b[38;5;241m.\u001b[39mvector_count)\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mprocess_uploaded_pdfs\u001b[1;34m(file_paths, session_id)\u001b[0m\n\u001b[0;32m      4\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[1;32m----> 6\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     docs\u001b[38;5;241m.\u001b[39mextend(loader\u001b[38;5;241m.\u001b[39mload())\n\u001b[0;32m      8\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_split(docs)\n",
      "File \u001b[1;32mc:\\Users\\Dikshit\\miniconda3\\envs\\pdfbot\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:281\u001b[0m, in \u001b[0;36mPyPDFLoader.__init__\u001b[1;34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    240\u001b[0m     file_path: Union[\u001b[38;5;28mstr\u001b[39m, PurePath],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m     extraction_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    251\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[0;32m    254\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m        `aload` methods to retrieve parsed documents with content and metadata.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m PyPDFParser(\n\u001b[0;32m    283\u001b[0m         password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[0;32m    284\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m         extraction_kwargs\u001b[38;5;241m=\u001b[39mextraction_kwargs,\n\u001b[0;32m    291\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dikshit\\miniconda3\\envs\\pdfbot\\lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:140\u001b[0m, in \u001b[0;36mBasePDFLoader.__init__\u001b[1;34m(self, file_path, headers)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not a valid file or url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)\n",
      "\u001b[1;31mValueError\u001b[0m: File path Data/Brown-Giving-PsychSci-2003.pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "# Cell 4: point to your PDF(s)\n",
    "uploaded = [\"Data/Brown-Giving-PsychSci-2003.pdf\"]  # adjust path as needed\n",
    "session = str(uuid.uuid4())\n",
    "vector_store = process_uploaded_pdfs(uploaded, session)\n",
    "\n",
    "# Check how many vectors you now have\n",
    "print(\"Vectors upserted:\", vector_store.client.describe_index(INDEX_NAME).namespaces[session].vector_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67339eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: port your helper logic, now using load_pdf_file\n",
    "from src.helper import load_pdf_directory, text_split, download_hugging_face_embeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "def process_uploaded_pdfs(data_dir, session_id):\n",
    "    \"\"\"\n",
    "    1) Loads all PDFs from a directory via load_pdf_file\n",
    "    2) Splits into chunks via text_split\n",
    "    3) Embeds with download_hugging_face_embeddings\n",
    "    4) Ensures the INDEX_NAME exists in Pinecone\n",
    "    5) Upserts into PineconeVectorStore under namespace=session_id\n",
    "    \"\"\"\n",
    "    # 1. Load & chunk\n",
    "    documents    = load_pdf_directory(data_dir)       # returns List[Document]\n",
    "    text_chunks  = text_split(documents)         # returns List[DocumentChunk]\n",
    "\n",
    "    # 2. Get embeddings instance\n",
    "    embeddings   = download_hugging_face_embeddings()\n",
    "\n",
    "    # 3. Ensure index exists\n",
    "    existing = pc.list_indexes()                 # returns List[str]\n",
    "    if INDEX_NAME not in existing:\n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=384,                       # must match your embedder\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud = \"aws\",\n",
    "                region = \"us-east-1\"\n",
    "    )\n",
    "        )\n",
    "        print(f\"➡️ Created index '{INDEX_NAME}'\")\n",
    "    else:\n",
    "        print(f\"✅ Index '{INDEX_NAME}' already exists\")\n",
    "\n",
    "    # 4. Upsert chunks into Pinecone under this session namespace\n",
    "    vs = PineconeVectorStore.from_documents(\n",
    "        documents=text_chunks,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings,\n",
    "        namespace=session_id\n",
    "    )\n",
    "\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73463258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9da601a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Created index 'pdfbot'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PineconeVectorStore' object has no attribute 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m vs \u001b[38;5;241m=\u001b[39m process_uploaded_pdfs(data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/\u001b[39m\u001b[38;5;124m\"\u001b[39m, session_id\u001b[38;5;241m=\u001b[39msession)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# confirm\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectors in namespace:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m----> 7\u001b[0m       \u001b[43mvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe_index(INDEX_NAME)\n\u001b[0;32m      8\u001b[0m          \u001b[38;5;241m.\u001b[39mnamespaces[session]\n\u001b[0;32m      9\u001b[0m          \u001b[38;5;241m.\u001b[39mvector_count\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PineconeVectorStore' object has no attribute 'client'"
     ]
    }
   ],
   "source": [
    "# Cell 4: point to your PDF directory instead of individual files\n",
    "session = str(uuid.uuid4())\n",
    "vs = process_uploaded_pdfs(data_dir=\"Data/\", session_id=session)\n",
    "\n",
    "# confirm\n",
    "print(\"Vectors in namespace:\", \n",
    "      vs.client.describe_index(INDEX_NAME)\n",
    "         .namespaces[session]\n",
    "         .vector_count\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79b29d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x227f2d9e9b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0acac453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "    {\n",
       "        \"name\": \"medicalbot\",\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"medicalbot-m2e5ynz.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"vector_type\": \"dense\",\n",
       "        \"dimension\": 384,\n",
       "        \"deletion_protection\": \"disabled\",\n",
       "        \"tags\": null\n",
       "    },\n",
       "    {\n",
       "        \"name\": \"pdfbot\",\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"pdfbot-m2e5ynz.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"vector_type\": \"dense\",\n",
       "        \"dimension\": 384,\n",
       "        \"deletion_protection\": \"disabled\",\n",
       "        \"tags\": null\n",
       "    }\n",
       "]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_indexes = pc.list_indexes()\n",
    "existing_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c7cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
